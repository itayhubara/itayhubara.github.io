---
title: "NVIDIA Nemotron 3: Efficient and Open Intelligence"
collection: publications
permalink: /publication/2025-12-23-nvidia-nemotron-3
excerpt: 'We introduce the Nemotron 3 family of models - Nano, Super, and Ultra. These models deliver strong agentic, reasoning, and conversational capabilities using a Mixture-of-Experts hybrid Mamba-Transformer architecture.'
date: 2025-12-23
venue: 'arXiv'
paperurl: 'https://arxiv.org/pdf/2512.20856'
citation: 'NVIDIA, Itay Hubara, et al. (2025). "NVIDIA Nemotron 3: Efficient and Open Intelligence." <i>arXiv preprint arXiv:2512.20856</i>.'
---
We introduce the Nemotron 3 family of models - Nano, Super, and Ultra. These models deliver strong agentic, reasoning, and conversational capabilities. The Nemotron 3 family uses a Mixture-of-Experts hybrid Mamba-Transformer architecture to provide best-in-class throughput and context lengths of up to 1M tokens. Super and Ultra models are trained with NVFP4 and incorporate LatentMoE, a novel approach for efficient expert routing.

[Download paper here](https://arxiv.org/pdf/2512.20856)
